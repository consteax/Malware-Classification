import os,glob,numpy
os.chdir('/home/constdec/Desktop/malimg_dataset') # the parent folder with sub-folders

list_fams = os.listdir(os.getcwd()) # vector of strings with family names

no_imgs = [] # No. of samples per family

for i in range(len(list_fams)):
 os.chdir(list_fams[i])
 len1 = len(glob.glob('*.png')) # assuming the images are stored as 'png'
 no_imgs.append(len1)
 os.chdir('..')

total = sum(no_imgs) # total number of all samples
y = numpy.zeros(total) # label vector

temp1 = numpy.zeros(len(no_imgs)+1)
temp1[1:len(temp1)]=no_imgs
temp2 = int(temp1[0]) # now temp2 is [0 no_imgs]

for jj in range(len(no_imgs)):
    temp3 = temp2 +int(temp1[jj+1])
    for ii in range(temp2,temp3):
       y[ii] = jj
    temp2 = temp2+ int(temp1[jj+1])

import Image, leargist

X = numpy.zeros((sum(no_imgs), 320))  # Feature Matrix
cnt = 0
for i in range(len(list_fams)):
    os.chdir(list_fams[i])
    img_list = glob.glob('*.png')  # Getting only 'png' files in a folder
    for j in range(len(img_list)):
        im = Image.open(img_list[j])
        im1 = im.resize((64, 64), Image.ANTIALIAS);  # for faster computation
        des = leargist.color_gist(im1)
        X[cnt] = des[0:320]
        cnt = cnt + 1
    os.chdir('..')
import random
from sklearn.cross_validation import StratifiedKFold
from sklearn.utils import shuffle

n_samples, n_features = X.shape
p = range(n_samples)  # an index array, 0:n_samples
random.seed(random.random())
random.shuffle(p)  # the index array is now shuffled

X, y = X[p], y[p]  # both the arrays are now shuffled

import time
from sklearn.cluster import DBSCAN
from sklearn import metrics
import numpy as np

from sklearn.preprocessing import StandardScaler

conf_mat = numpy.zeros((len(no_imgs), len(no_imgs)))  # Initializing the Confusion Matrix


# Compute DBSCAN
db = DBSCAN(eps=0.3, min_samples=10).fit(X)
core_samples_mask = np.zeros_like(db.labels_, dtype=bool)
core_samples_mask[db.core_sample_indices_] = True
labels = db.labels_

# Number of clusters in labels, ignoring noise if present.
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)

print('Estimated number of clusters: %d' % n_clusters_)
print("Homogeneity: %0.3f" % metrics.homogeneity_score(y, labels))
print("Completeness: %0.3f" % metrics.completeness_score(y, labels))
print("V-measure: %0.3f" % metrics.v_measure_score(y, labels))
print("Adjusted Rand Index: %0.3f"
      % metrics.adjusted_rand_score(y, labels))
print("Adjusted Mutual Information: %0.3f"
      % metrics.adjusted_mutual_info_score(y, labels))
print("Silhouette Coefficient: %0.3f"
      % metrics.silhouette_score(X, labels))

##############################################################################
# Plot result
import matplotlib.pyplot as plt

# Black removed and is used for noise instead.
unique_labels = set(labels)
colors = plt.get_cmap('Spectral')(np.linspace(0, 1, len(unique_labels)))
for k, col in zip(unique_labels, colors):
    if k == -1:
        # Black used for noise.
        col = 'k'

    class_member_mask = (labels == k)

    xy = X[class_member_mask & core_samples_mask]
    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,
             markeredgecolor='k', markersize=14)

    xy = X[class_member_mask & ~core_samples_mask]
    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col,
             markeredgecolor='k', markersize=6)

plt.title('Estimated number of clusters: %d' % n_clusters_)
plt.show()